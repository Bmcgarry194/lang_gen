{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chain Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A brute force solution. Shannon proposed an interesting scheme to generate text according to a Markov model of order 1.\n",
    "\n",
    "To construct [an order 1 model] for example:\n",
    "1. Open a book at random and selects a letter at random on the page and record the letter. \n",
    "2. The book is then opened to another page and one reads until this letter is encountered. The succeeding letter is then recorded. \n",
    "3. Turning to another page this second letter is searched for and the succeeding letter recorded, etc. \n",
    "\n",
    "It would be interesting if further approximations could be constructed, but the labor involved becomes enormous at the next stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import Dict, List\n",
    "from collections import defaultdict\n",
    "import author\n",
    "\n",
    "def read_text(path: str) -> str:    \n",
    "    with open(path) as f:\n",
    "        text = f.read().strip().lower().split()\n",
    "    return text\n",
    "\n",
    "def word_frequencies(text: str) -> Dict[str, List[str]]:\n",
    "    '''Create a dictionary defining an order 1 model of language'''\n",
    "    \n",
    "    word_freqs = defaultdict(lambda: [])\n",
    "    \n",
    "    for first_w, second_w in list(zip(text, text[1:])):\n",
    "        word_freqs[first_w].append(second_w)\n",
    "    return word_freqs\n",
    "\n",
    "def create_sentence(text: str, word_freqs: Dict[str, List[str]]) -> str:\n",
    "    \n",
    "    first_word = np.random.choice(text)\n",
    "    \n",
    "    chain = [first_word]\n",
    "\n",
    "    while not '.' in chain[-1]:\n",
    "        chain.append(np.random.choice(word_freqs[chain[-1]]))\n",
    "        \n",
    "    return ' '.join(chain)\n",
    "\n",
    "def paragraph(text: str, sentence_num: int=3) -> str:\n",
    "    \n",
    "    word_freqs = word_frequencies(text)\n",
    "    paragraph = []\n",
    "    \n",
    "    for _ in range(sentence_num):\n",
    "        paragraph.append(create_sentence(text, word_freqs))\n",
    "\n",
    "    return '\\n\\n'.join(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = read_text('data/dracula.txt')\n",
    "\n",
    "print(paragraph(text, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'follow that conception, which does not so many different interests of construction, the simplicity is the object of things that is, on the history of modality being as much of thought.'"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import author\n",
    "\n",
    "shelly = author.Author()\n",
    "\n",
    "shelly.read_text(path='data/pure_reason.txt')\n",
    "\n",
    "# shelly.create_word_frequencies()\n",
    "\n",
    "shelly.create_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empirical laws which a seriesâ€”its parts do not sooner suggest itself exist only as a synthetical propositions is also no means of all the world is, of virtue, who acknowledges the singular proposition.\n",
      "\n",
      "example, a discipline can i have a doctrine of the conception of experience.\n",
      "\n",
      "of the respective strength from each other spheres in general, to a free action.\n"
     ]
    }
   ],
   "source": [
    "print(shelly.create_paragraph(sentence_num=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [(1, 2), (2, 1), (3, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sort(key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2), (2, 1), (3, 0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def first(x):\n",
    "    return x[0]\n",
    "\n",
    "sorted(a, key=first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 4, 5]\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
